#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI ë¦¬ì•¡ì…˜ ë¶„ì„ ì„œë¹„ìŠ¤
OpenAI GPT, Anthropic Claude, ë˜ëŠ” ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•œ ê¸°ì‚¬ ë¶„ì„
"""

import logging
import time
import re
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
import asyncio
from abc import ABC, abstractmethod

# AI ëª¨ë¸ ê´€ë ¨ imports (ì¡°ê±´ë¶€)
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False
    anthropic = None

# ë¡œì»¬ ëª¨ë¸ ê´€ë ¨ imports (ì¡°ê±´ë¶€)
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

from app.models.ai_reaction import (
    ArticleAnalysisRequest,
    ReactionAnalysisResult,
    SentimentAnalysis,
    KeywordExtraction,
    CommentGeneration,
    ArticleSummary,
    QuestionGeneration,
    ToneAnalysis,
    FactCheckResult,
    SimpleReaction,
    SimplifiedResponse,
    SentimentType,
    ReactionType
)

logger = logging.getLogger(__name__)


class BaseAIProvider(ABC):
    """AI ì œê³µì ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        self.model_version = "unknown"
    
    @abstractmethod
    async def analyze_sentiment(self, text: str) -> SentimentAnalysis:
        """ê°ì • ë¶„ì„"""
        pass
    
    @abstractmethod
    async def extract_keywords(self, text: str, max_keywords: int = 10) -> KeywordExtraction:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        pass
    
    @abstractmethod
    async def generate_comments(self, text: str, max_comments: int = 5) -> CommentGeneration:
        """ëŒ“ê¸€ ìƒì„±"""
        pass
    
    @abstractmethod
    async def summarize_article(self, text: str) -> ArticleSummary:
        """ê¸°ì‚¬ ìš”ì•½"""
        pass
    
    @abstractmethod
    async def generate_questions(self, text: str, max_questions: int = 5) -> QuestionGeneration:
        """ì§ˆë¬¸ ìƒì„±"""
        pass


class OpenAIProvider(BaseAIProvider):
    """OpenAI GPT ê¸°ë°˜ AI ì œê³µì"""
    
    def __init__(self, api_key: str, model: str = "gpt-3.5-turbo"):
        super().__init__(api_key)
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip install openai")
        
        openai.api_key = api_key
        self.model = model
        self.model_version = f"openai-{model}"
        logger.info(f"OpenAI ì œê³µì ì´ˆê¸°í™”: {self.model}")
    
    async def _call_openai(self, messages: List[Dict[str, str]], max_tokens: int = 1000) -> str:
        """OpenAI API í˜¸ì¶œ"""
        try:
            response = await openai.ChatCompletion.acreate(
                model=self.model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=0.7
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            raise
    
    async def analyze_sentiment(self, text: str) -> SentimentAnalysis:
        """ê°ì • ë¶„ì„"""
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¸ì •, ë¶€ì •, ì¤‘ë¦½ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³  ê°ê°ì˜ ì ìˆ˜ë¥¼ 0-1 ì‚¬ì´ë¡œ ì œê³µí•˜ì„¸ìš”."},
            {"role": "user", "content": f"ë‹¤ìŒ ê¸°ì‚¬ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{text}"}
        ]
        
        response = await self._call_openai(messages)
        
        # ê°„ë‹¨í•œ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
        if "ê¸ì •" in response.lower() or "positive" in response.lower():
            sentiment = SentimentType.POSITIVE
            positive_score = 0.8
            negative_score = 0.1
            neutral_score = 0.1
        elif "ë¶€ì •" in response.lower() or "negative" in response.lower():
            sentiment = SentimentType.NEGATIVE
            positive_score = 0.1
            negative_score = 0.8
            neutral_score = 0.1
        else:
            sentiment = SentimentType.NEUTRAL
            positive_score = 0.3
            negative_score = 0.2
            neutral_score = 0.5
        
        return SentimentAnalysis(
            sentiment=sentiment,
            confidence=0.85,
            positive_score=positive_score,
            negative_score=negative_score,
            neutral_score=neutral_score,
            explanation=response
        )
    
    async def extract_keywords(self, text: str, max_keywords: int = 10) -> KeywordExtraction:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        messages = [
            {"role": "system", "content": f"ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìµœëŒ€ {max_keywords}ê°œì˜ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”."},
            {"role": "user", "content": f"ë‹¤ìŒ ê¸°ì‚¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:\n\n{text}"}
        ]
        
        response = await self._call_openai(messages)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒŒì‹±)
        keywords = []
        for line in response.split('\n'):
            if line.strip() and ('í‚¤ì›Œë“œ' in line or 'â€¢' in line or '-' in line):
                keyword = re.sub(r'[â€¢\-\d\.\s]+', '', line).strip()
                if keyword and len(keyword) > 1:
                    keywords.append(keyword)
        
        # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if not keywords:
            keywords = ["AI", "ê¸°ìˆ ", "í˜ì‹ ", "ë°œì „", "ë³€í™”"]
        
        keyword_scores = {kw: 1.0 - (i * 0.1) for i, kw in enumerate(keywords[:max_keywords])}
        
        return KeywordExtraction(
            keywords=keywords[:max_keywords],
            keyword_scores=keyword_scores,
            explanation=response
        )
    
    async def generate_comments(self, text: str, max_comments: int = 5) -> CommentGeneration:
        """ëŒ“ê¸€ ìƒì„±"""
        messages = [
            {"role": "system", "content": f"ë‹¹ì‹ ì€ ê¸°ì‚¬ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ“ê¸€ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {max_comments}ê°œì˜ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ ëŒ“ê¸€ì„ ìƒì„±í•˜ì„¸ìš”."},
            {"role": "user", "content": f"ë‹¤ìŒ ê¸°ì‚¬ì— ëŒ€í•œ ëŒ“ê¸€ì„ ìƒì„±í•´ì£¼ì„¸ìš”:\n\n{text}"}
        ]
        
        response = await self._call_openai(messages)
        
        # ëŒ“ê¸€ ì¶”ì¶œ
        comments = []
        comment_types = []
        
        for line in response.split('\n'):
            if line.strip() and ('"' in line or 'â€¢' in line or line.startswith(('1.', '2.', '3.', '4.', '5.'))):
                comment = re.sub(r'[â€¢\-\d\.\s"]+', '', line, count=1).strip()
                if comment and len(comment) > 10:
                    comments.append(comment)
                    comment_types.append("ì¼ë°˜í˜•")
        
        # ê¸°ë³¸ ëŒ“ê¸€ì´ ì—†ìœ¼ë©´ ìƒì„±
        if not comments:
            comments = [
                "ì •ë§ í¥ë¯¸ë¡œìš´ ë‚´ìš©ì´ë„¤ìš”! ì•ìœ¼ë¡œì˜ ë°œì „ì´ ê¸°ëŒ€ë©ë‹ˆë‹¤. ğŸ‘",
                "ì´ëŸ° í˜ì‹ ì ì¸ ê¸°ìˆ ì´ ìš°ë¦¬ ìƒí™œì— ì–´ë–¤ ë³€í™”ë¥¼ ê°€ì ¸ì˜¬ì§€ ê¶ê¸ˆí•˜ë„¤ìš”.",
                "ê¸°ì‚¬ ì˜ ì½ì—ˆìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¢‹ê² ì–´ìš”!"
            ]
            comment_types = ["ê¸ì •í˜•", "ì§ˆë¬¸í˜•", "ì •ë³´í˜•"]
        
        return CommentGeneration(
            comments=comments[:max_comments],
            comment_types=comment_types[:max_comments],
            explanation=response
        )
    
    async def summarize_article(self, text: str) -> ArticleSummary:
        """ê¸°ì‚¬ ìš”ì•½"""
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸°ì‚¬ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 3-5ê°œì˜ í•µì‹¬ í¬ì¸íŠ¸ì™€ í•œ ì¤„ ìš”ì•½ì„ ì œê³µí•˜ì„¸ìš”."},
            {"role": "user", "content": f"ë‹¤ìŒ ê¸°ì‚¬ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{text}"}
        ]
        
        response = await self._call_openai(messages)
        
        # ìš”ì•½ í¬ì¸íŠ¸ ì¶”ì¶œ
        summary_points = []
        one_line_summary = ""
        
        lines = response.split('\n')
        for line in lines:
            if line.strip() and ('â€¢' in line or '-' in line or line.startswith(('1.', '2.', '3.'))):
                point = re.sub(r'[â€¢\-\d\.\s]+', '', line, count=1).strip()
                if point:
                    summary_points.append(point)
            elif "ìš”ì•½" in line and len(line.strip()) > 20:
                one_line_summary = line.strip()
        
        if not summary_points:
            summary_points = [
                "ìƒˆë¡œìš´ ê¸°ìˆ  í˜ì‹ ì´ ì£¼ëª©ë°›ê³  ìˆìŒ",
                "í–¥í›„ ì‚°ì—… ì „ë°˜ì— ê¸ì •ì  ì˜í–¥ ì˜ˆìƒ",
                "ì§€ì†ì ì¸ ì—°êµ¬ ê°œë°œì´ í•„ìš”í•œ ìƒí™©"
            ]
        
        if not one_line_summary:
            one_line_summary = "ê¸°ìˆ  í˜ì‹ ì„ í†µí•œ ë¯¸ë˜ ë³€í™”ì— ëŒ€í•œ ì „ë§ì„ ë‹¤ë£¬ ê¸°ì‚¬"
        
        return ArticleSummary(
            summary_points=summary_points,
            one_line_summary=one_line_summary,
            explanation=response
        )
    
    async def generate_questions(self, text: str, max_questions: int = 5) -> QuestionGeneration:
        """ì§ˆë¬¸ ìƒì„±"""
        messages = [
            {"role": "system", "content": f"ë‹¹ì‹ ì€ ê¸°ì‚¬ë¥¼ ì½ê³  ê´€ë ¨ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {max_questions}ê°œì˜ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”."},
            {"role": "user", "content": f"ë‹¤ìŒ ê¸°ì‚¬ì— ëŒ€í•œ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”:\n\n{text}"}
        ]
        
        response = await self._call_openai(messages)
        
        # ì§ˆë¬¸ ì¶”ì¶œ
        questions = []
        question_types = []
        
        for line in response.split('\n'):
            if line.strip() and ('?' in line or 'ï¼Ÿ' in line):
                question = line.strip()
                if len(question) > 10:
                    questions.append(question)
                    if "ì–¸ì œ" in question or "ì‹œê¸°" in question:
                        question_types.append("ì‹œê¸°í˜•")
                    elif "ì–´ë–»ê²Œ" in question or "ë°©ë²•" in question:
                        question_types.append("ë°©ë²•í˜•")
                    elif "ì™œ" in question or "ì´ìœ " in question:
                        question_types.append("ì´ìœ í˜•")
                    else:
                        question_types.append("ì¼ë°˜í˜•")
        
        # ê¸°ë³¸ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ìƒì„±
        if not questions:
            questions = [
                "ì´ ê¸°ìˆ ì˜ ìƒìš©í™” ì‹œê¸°ëŠ” ì–¸ì œì¯¤ ì˜ˆìƒë˜ë‚˜ìš”?",
                "ê¸°ì¡´ ê¸°ìˆ ê³¼ ë¹„êµí–ˆì„ ë•Œ ì–´ë–¤ ì¥ì ì´ ìˆë‚˜ìš”?",
                "ë„ì… ì‹œ ì˜ˆìƒë˜ëŠ” ë¹„ìš©ì€ ì–´ëŠ ì •ë„ì¸ê°€ìš”?",
                "ë³´ì•ˆì´ë‚˜ ì•ˆì „ì„± ì¸¡ë©´ì—ì„œëŠ” ì–´ë–¤ê°€ìš”?",
                "ì¼ë°˜ ì‚¬ìš©ìë„ ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆì„ê¹Œìš”?"
            ]
            question_types = ["ì‹œê¸°í˜•", "ë¹„êµí˜•", "ë¹„ìš©í˜•", "ì•ˆì „í˜•", "ì ‘ê·¼ì„±í˜•"]
        
        return QuestionGeneration(
            questions=questions[:max_questions],
            question_types=question_types[:max_questions],
            explanation=response
        )


class MockAIProvider(BaseAIProvider):
    """í…ŒìŠ¤íŠ¸ìš© ëª¨ì˜ AI ì œê³µì"""
    
    def __init__(self):
        super().__init__()
        self.model_version = "mock-ai-v1.0"
        logger.info("ëª¨ì˜ AI ì œê³µì ì´ˆê¸°í™”")
    
    async def analyze_sentiment(self, text: str) -> SentimentAnalysis:
        """ëª¨ì˜ ê°ì • ë¶„ì„"""
        await asyncio.sleep(0.5)  # ì‹¤ì œ API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„
        positive_words = ["ì¢‹", "í›Œë¥­", "í˜ì‹ ", "ë°œì „", "ì„±ê³µ", "í¬ë§", "ê¸ì •"]
        negative_words = ["ë‚˜ì˜", "ë¬¸ì œ", "ìœ„í—˜", "ì‹¤íŒ¨", "ìš°ë ¤", "ë¶€ì •"]
        
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        
        if positive_count > negative_count:
            sentiment = SentimentType.POSITIVE
            positive_score = 0.7 + (positive_count * 0.05)
            negative_score = 0.1
            neutral_score = 1.0 - positive_score - negative_score
        elif negative_count > positive_count:
            sentiment = SentimentType.NEGATIVE
            negative_score = 0.7 + (negative_count * 0.05)
            positive_score = 0.1
            neutral_score = 1.0 - positive_score - negative_score
        else:
            sentiment = SentimentType.NEUTRAL
            positive_score = 0.3
            negative_score = 0.2
            neutral_score = 0.5
        
        return SentimentAnalysis(
            sentiment=sentiment,
            confidence=0.85,
            positive_score=min(positive_score, 1.0),
            negative_score=min(negative_score, 1.0),
            neutral_score=max(neutral_score, 0.0),
            explanation=f"í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„: ê¸ì • í‚¤ì›Œë“œ {positive_count}ê°œ, ë¶€ì • í‚¤ì›Œë“œ {negative_count}ê°œ ë°œê²¬"
        )
    
    async def extract_keywords(self, text: str, max_keywords: int = 10) -> KeywordExtraction:
        """ëª¨ì˜ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        await asyncio.sleep(0.3)
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” TF-IDFë‚˜ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
        common_words = {"ì´", "ê°€", "ì„", "ë¥¼", "ì˜", "ì—", "ëŠ”", "ì€", "ê³¼", "ì™€", "ë¡œ", "ìœ¼ë¡œ", "ì—ì„œ", "í•˜ê³ ", "ìˆë‹¤", "ìˆëŠ”", "ê²ƒ", "ìˆ˜", "ë“±"}
        
        words = re.findall(r'[ê°€-í£A-Za-z]+', text)
        word_freq = {}
        
        for word in words:
            if len(word) > 1 and word not in common_words:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # ë¹ˆë„ìˆœ ì •ë ¬
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        keywords = [word for word, freq in sorted_words[:max_keywords]]
        
        # ì ìˆ˜ ê³„ì‚°
        max_freq = max(word_freq.values()) if word_freq else 1
        keyword_scores = {word: freq / max_freq for word, freq in sorted_words[:max_keywords]}
        
        return KeywordExtraction(
            keywords=keywords,
            keyword_scores=keyword_scores,
            explanation=f"ë¹ˆë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ: ì´ {len(word_freq)}ê°œ ë‹¨ì–´ ì¤‘ ìƒìœ„ {len(keywords)}ê°œ ì„ ë³„"
        )
    
    async def generate_comments(self, text: str, max_comments: int = 5) -> CommentGeneration:
        """ëª¨ì˜ ëŒ“ê¸€ ìƒì„±"""
        await asyncio.sleep(0.7)
        
        # í…œí”Œë¦¿ ê¸°ë°˜ ëŒ“ê¸€ ìƒì„±
        templates = [
            "ì •ë§ í¥ë¯¸ë¡œìš´ ë‚´ìš©ì´ë„¤ìš”! ì•ìœ¼ë¡œì˜ ë°œì „ì´ ê¸°ëŒ€ë©ë‹ˆë‹¤. ğŸ‘",
            "ì´ëŸ° í˜ì‹ ì ì¸ ê¸°ìˆ ì´ ìš°ë¦¬ ìƒí™œì— ì–´ë–¤ ë³€í™”ë¥¼ ê°€ì ¸ì˜¬ì§€ ê¶ê¸ˆí•˜ë„¤ìš”.",
            "ê¸°ì‚¬ ì˜ ì½ì—ˆìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¢‹ê² ì–´ìš”! ğŸ“š",
            "ì „ë¬¸ê°€ë“¤ì˜ ì˜ê²¬ë„ í•¨ê»˜ ë“¤ì–´ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤.",
            "ì‹¤ì œ ì ìš© ì‚¬ë¡€ê°€ ìˆë‹¤ë©´ ì†Œê°œí•´ì£¼ì„¸ìš”!",
            "ì´ ë¶„ì•¼ì— ëŒ€í•´ ë” ê³µë¶€í•´ë³´ê³  ì‹¶ì–´ì¡Œì–´ìš”.",
            "ì •ë¶€ ì •ì±…ì€ ì–´ë–»ê²Œ ë ê¹Œìš”?",
            "ë‹¤ë¥¸ ë‚˜ë¼ì˜ ìƒí™©ì€ ì–´ë–¤ì§€ë„ ê¶ê¸ˆí•©ë‹ˆë‹¤."
        ]
        
        import random
        selected_comments = random.sample(templates, min(max_comments, len(templates)))
        comment_types = ["ê¸ì •í˜•", "ì§ˆë¬¸í˜•", "ì •ë³´í˜•", "ì˜ê²¬í˜•", "ìš”ì²­í˜•"][:len(selected_comments)]
        
        return CommentGeneration(
            comments=selected_comments,
            comment_types=comment_types,
            explanation="í…œí”Œë¦¿ ê¸°ë°˜ ëŒ“ê¸€ ìƒì„±ìœ¼ë¡œ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ ëŒ“ê¸€ì„ ì œê³µ"
        )
    
    async def summarize_article(self, text: str) -> ArticleSummary:
        """ëª¨ì˜ ê¸°ì‚¬ ìš”ì•½"""
        await asyncio.sleep(0.4)
        
        # ê°„ë‹¨í•œ ë¬¸ì¥ ê¸°ë°˜ ìš”ì•½
        sentences = re.split(r'[.!?]\s+', text)
        important_sentences = [s.strip() for s in sentences if len(s.strip()) > 20][:3]
        
        summary_points = [f"â€¢ {sentence}" for sentence in important_sentences]
        one_line_summary = important_sentences[0] if important_sentences else "ê¸°ì‚¬ ë‚´ìš©ì— ëŒ€í•œ ìš”ì•½"
        
        return ArticleSummary(
            summary_points=summary_points,
            one_line_summary=one_line_summary,
            explanation="ë¬¸ì¥ ê¸¸ì´ ê¸°ë°˜ ì¤‘ìš” ë¬¸ì¥ ì¶”ì¶œì„ í†µí•œ ìš”ì•½"
        )
    
    async def generate_questions(self, text: str, max_questions: int = 5) -> QuestionGeneration:
        """ëª¨ì˜ ì§ˆë¬¸ ìƒì„±"""
        await asyncio.sleep(0.6)
        
        # í…œí”Œë¦¿ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±
        question_templates = [
            "ì´ ê¸°ìˆ ì˜ ìƒìš©í™” ì‹œê¸°ëŠ” ì–¸ì œì¯¤ ì˜ˆìƒë˜ë‚˜ìš”?",
            "ê¸°ì¡´ ê¸°ìˆ ê³¼ ë¹„êµí–ˆì„ ë•Œ ì–´ë–¤ ì¥ì ì´ ìˆë‚˜ìš”?",
            "ë„ì… ì‹œ ì˜ˆìƒë˜ëŠ” ë¹„ìš©ì€ ì–´ëŠ ì •ë„ì¸ê°€ìš”?",
            "ë³´ì•ˆì´ë‚˜ ì•ˆì „ì„± ì¸¡ë©´ì—ì„œëŠ” ì–´ë–¤ê°€ìš”?",
            "ì¼ë°˜ ì‚¬ìš©ìë„ ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆì„ê¹Œìš”?",
            "ì´ ë¶„ì•¼ì˜ ë¯¸ë˜ ì „ë§ì€ ì–´ë–»ê²Œ ë³´ì‹œë‚˜ìš”?",
            "ê´€ë ¨ ê·œì œë‚˜ ë²•ì  ì´ìŠˆëŠ” ì—†ë‚˜ìš”?",
            "í•´ì™¸ ë™í–¥ì€ ì–´ë–¤ ìƒí™©ì¸ê°€ìš”?"
        ]
        
        import random
        selected_questions = random.sample(question_templates, min(max_questions, len(question_templates)))
        question_types = ["ì‹œê¸°í˜•", "ë¹„êµí˜•", "ë¹„ìš©í˜•", "ì•ˆì „í˜•", "ì ‘ê·¼ì„±í˜•"][:len(selected_questions)]
        
        return QuestionGeneration(
            questions=selected_questions,
            question_types=question_types,
            explanation="í…œí”Œë¦¿ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±ìœ¼ë¡œ ë‹¤ì–‘í•œ ê´€ì ì˜ ì§ˆë¬¸ì„ ì œê³µ"
        )


class AIReactionService:
    """AI ë¦¬ì•¡ì…˜ ë¶„ì„ ì„œë¹„ìŠ¤ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, provider: BaseAIProvider):
        self.provider = provider
        logger.info(f"AI ë¦¬ì•¡ì…˜ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”: {provider.model_version}")
    
    async def analyze_article(self, request: ArticleAnalysisRequest) -> ReactionAnalysisResult:
        """ê¸°ì‚¬ ì „ì²´ ë¶„ì„"""
        start_time = time.time()
        
        try:
            result = ReactionAnalysisResult(
                analysis_timestamp=datetime.now().isoformat(),
                processing_time=0.0,
                model_version=self.provider.model_version,
                success=True
            )
            
            # ê° ë¶„ì„ íƒ€ì…ë³„ ì²˜ë¦¬
            tasks = []
            
            if ReactionType.SENTIMENT in request.analysis_types:
                tasks.append(self._analyze_sentiment(request.article_text))
            
            if ReactionType.KEYWORDS in request.analysis_types:
                tasks.append(self._extract_keywords(request.article_text, request.max_keywords))
            
            if ReactionType.COMMENTS in request.analysis_types:
                tasks.append(self._generate_comments(request.article_text, request.max_comments))
            
            if ReactionType.SUMMARY in request.analysis_types:
                tasks.append(self._summarize_article(request.article_text))
            
            if ReactionType.QUESTIONS in request.analysis_types:
                tasks.append(self._generate_questions(request.article_text, request.max_questions))
            
            # ë³‘ë ¬ ì²˜ë¦¬
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ í• ë‹¹
            task_index = 0
            if ReactionType.SENTIMENT in request.analysis_types:
                if not isinstance(results[task_index], Exception):
                    result.sentiment_analysis = results[task_index]
                task_index += 1
            
            if ReactionType.KEYWORDS in request.analysis_types:
                if not isinstance(results[task_index], Exception):
                    result.keyword_extraction = results[task_index]
                task_index += 1
            
            if ReactionType.COMMENTS in request.analysis_types:
                if not isinstance(results[task_index], Exception):
                    result.comment_generation = results[task_index]
                task_index += 1
            
            if ReactionType.SUMMARY in request.analysis_types:
                if not isinstance(results[task_index], Exception):
                    result.article_summary = results[task_index]
                task_index += 1
            
            if ReactionType.QUESTIONS in request.analysis_types:
                if not isinstance(results[task_index], Exception):
                    result.question_generation = results[task_index]
                task_index += 1
            
            result.processing_time = time.time() - start_time
            return result
            
        except Exception as e:
            logger.error(f"ê¸°ì‚¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return ReactionAnalysisResult(
                analysis_timestamp=datetime.now().isoformat(),
                processing_time=time.time() - start_time,
                model_version=self.provider.model_version,
                success=False,
                error_message=str(e)
            )
    
    async def _analyze_sentiment(self, text: str) -> SentimentAnalysis:
        """ê°ì • ë¶„ì„ ë˜í¼"""
        return await self.provider.analyze_sentiment(text)
    
    async def _extract_keywords(self, text: str, max_keywords: int) -> KeywordExtraction:
        """í‚¤ì›Œë“œ ì¶”ì¶œ ë˜í¼"""
        return await self.provider.extract_keywords(text, max_keywords)
    
    async def _generate_comments(self, text: str, max_comments: int) -> CommentGeneration:
        """ëŒ“ê¸€ ìƒì„± ë˜í¼"""
        return await self.provider.generate_comments(text, max_comments)
    
    async def _summarize_article(self, text: str) -> ArticleSummary:
        """ê¸°ì‚¬ ìš”ì•½ ë˜í¼"""
        return await self.provider.summarize_article(text)
    
    async def _generate_questions(self, text: str, max_questions: int) -> QuestionGeneration:
        """ì§ˆë¬¸ ìƒì„± ë˜í¼"""
        return await self.provider.generate_questions(text, max_questions)
    
    def convert_to_simple_format(self, result: ReactionAnalysisResult) -> SimplifiedResponse:
        """í”„ë¡ íŠ¸ì—”ë“œìš© ê°„ì†Œí™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        reactions = []
        
        if result.sentiment_analysis:
            sentiment_text = f"{result.sentiment_analysis.sentiment.value} ({result.sentiment_analysis.confidence*100:.0f}%)"
            reactions.append(SimpleReaction(
                type="ê°ì • ë¶„ì„",
                icon="ğŸ˜Š" if result.sentiment_analysis.sentiment == SentimentType.POSITIVE else 
                     "ğŸ˜”" if result.sentiment_analysis.sentiment == SentimentType.NEGATIVE else "ğŸ˜",
                result=sentiment_text,
                details=[result.sentiment_analysis.explanation]
            ))
        
        if result.keyword_extraction:
            reactions.append(SimpleReaction(
                type="í‚¤ì›Œë“œ ì¶”ì¶œ",
                icon="ğŸ”",
                result=f"{len(result.keyword_extraction.keywords)}ê°œ í‚¤ì›Œë“œ",
                details=result.keyword_extraction.keywords
            ))
        
        if result.comment_generation:
            reactions.append(SimpleReaction(
                type="ëŒ“ê¸€ ì œì•ˆ",
                icon="ğŸ’¬",
                result=f"{len(result.comment_generation.comments)}ê°œ ëŒ“ê¸€",
                details=result.comment_generation.comments
            ))
        
        if result.article_summary:
            reactions.append(SimpleReaction(
                type="ìš”ì•½",
                icon="ğŸ“",
                result="í•µì‹¬ ìš”ì•½",
                details=[result.article_summary.one_line_summary] + result.article_summary.summary_points
            ))
        
        if result.question_generation:
            reactions.append(SimpleReaction(
                type="ê´€ë ¨ ì§ˆë¬¸",
                icon="â“",
                result=f"{len(result.question_generation.questions)}ê°œ ì§ˆë¬¸",
                details=result.question_generation.questions
            ))
        
        return SimplifiedResponse(
            success=result.success,
            reactions=reactions,
            processing_time=result.processing_time,
            message="AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤." if result.success else f"ë¶„ì„ ì‹¤íŒ¨: {result.error_message}"
        )


# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•¨ìˆ˜ë“¤
def create_mock_service() -> AIReactionService:
    """ëª¨ì˜ AI ì„œë¹„ìŠ¤ ìƒì„±"""
    provider = MockAIProvider()
    return AIReactionService(provider)


def create_openai_service(api_key: str, model: str = "gpt-3.5-turbo") -> AIReactionService:
    """OpenAI ê¸°ë°˜ AI ì„œë¹„ìŠ¤ ìƒì„±"""
    if not OPENAI_AVAILABLE:
        raise ImportError("OpenAI íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install openai")
    
    provider = OpenAIProvider(api_key, model)
    return AIReactionService(provider)


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_ai_service: Optional[AIReactionService] = None


def get_ai_service() -> AIReactionService:
    """AI ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _ai_service
    if _ai_service is None:
        # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ì˜ ì„œë¹„ìŠ¤ ì‚¬ìš©
        _ai_service = create_mock_service()
        logger.info("ê¸°ë³¸ ëª¨ì˜ AI ì„œë¹„ìŠ¤ ìƒì„±ë¨")
    return _ai_service


def set_ai_service(service: AIReactionService):
    """AI ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •"""
    global _ai_service
    _ai_service = service
    logger.info(f"AI ì„œë¹„ìŠ¤ ì„¤ì •ë¨: {service.provider.model_version}")


if __name__ == "__main__":
    # ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
    async def test_service():
        print("ğŸ¤– AI ë¦¬ì•¡ì…˜ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
        
        service = create_mock_service()
        
        request = ArticleAnalysisRequest(
            article_text="""
            AI ê¸°ìˆ ì˜ ë°œì „ì´ ê°€ì†í™”ë˜ê³  ìˆë‹¤. 
            ìµœê·¼ ChatGPTì™€ ê°™ì€ ëŒ€í™”í˜• AIì˜ ë“±ì¥ìœ¼ë¡œ 
            ë§ì€ ì‚¬ëŒë“¤ì´ AI ê¸°ìˆ ì— ê´€ì‹¬ì„ ê°–ê²Œ ë˜ì—ˆë‹¤.
            """,
            analysis_types=[ReactionType.SENTIMENT, ReactionType.KEYWORDS, ReactionType.COMMENTS]
        )
        
        result = await service.analyze_article(request)
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {result.success}")
        print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
        
        if result.sentiment_analysis:
            print(f"ğŸ˜Š ê°ì •: {result.sentiment_analysis.sentiment}")
        
        if result.keyword_extraction:
            print(f"ğŸ” í‚¤ì›Œë“œ: {result.keyword_extraction.keywords}")
        
        # ê°„ì†Œí™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        simple_result = service.convert_to_simple_format(result)
        print(f"ğŸ“± ê°„ì†Œí™”ëœ ê²°ê³¼: {len(simple_result.reactions)}ê°œ ë¦¬ì•¡ì…˜")
    
    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import asyncio
    asyncio.run(test_service())
